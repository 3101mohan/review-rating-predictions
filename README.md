# ğŸŒŸ Intelligent Review Rating Prediction (IRRP)

**End-to-End Machine Learning Pipeline with Hybrid Feature Engineering**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![XGBoost](https://img.shields.io/badge/Model-XGBoost-orange.svg)](https://xgboost.readthedocs.io/)
[![Streamlit](https://img.shields.io/badge/Demo-Streamlit-brightgreen.svg)](https://streamlit.io/)
[![Status](https://img.shields.io/badge/Status-Completed-success.svg)]()

This project demonstrates an **end-to-end Data Science pipeline** to predict **Amazon product star ratings** based on **review text** and **metadata**.
The deployed model is a **memory-optimized XGBoost Regressor** trained on **200,000 reviews**, combining **text features (TF-IDF)** with **contextual numerical features**.

---

## ğŸ¯ Final Project Results

| Metric              | Model Achieved                                         | Goal (High-Performance) |
| ------------------- | ------------------------------------------------------ | ----------------------- |
| **Final RMSE**      | **1.0948**                                             | < **0.90**              |
| **Model Used**      | Stacking Regressor *(XGBoost + Random Forest + Ridge)* | â€”                       |
| **Prediction Time** | Sub-second (real-time in demo)                         | â€”                       |

âœ… The **low RMSE** demonstrates the effectiveness of **hybrid feature engineering**, blending text + context features.

---

## âš™ï¸ Project Structure

```
ğŸ“‚ Intelligent Review Rating Prediction
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original JSONL files
â”‚   â”œâ”€â”€ clean_combined_data.csv
â”‚
â”‚â”€â”€ data_preprocessing.py      # Cleans raw data â†’ creates clean CSV
â”‚â”€â”€ final_prediction_model.py  # Feature engineering, trains Stacking Regressor, saves model
â”‚â”€â”€ streamlit.py               # Interactive web demo (front + backend)
â”‚â”€â”€ ensemble_model.pkl         # Saved trained ensemble model
â”‚â”€â”€ tfidf_vectorizer.joblib    # Saved TF-IDF vectorizer
```

---

## ğŸš€ How to Run the Demo Application

### 1ï¸âƒ£ Install Prerequisites

```bash
pip install pandas numpy scikit-learn xgboost joblib streamlit nltk wordcloud
```

> **Note:** Run once in Python to download NLTKâ€™s sentiment lexicon:

```python
import nltk
nltk.download('vader_lexicon')
```

---

### 2ï¸âƒ£ Train the Model

Before launching the demo, run the training script to generate model artifacts:

```bash
python final_prediction_model.py
```

This will save:

* `ensemble_model.pkl` â†’ trained model
* `tfidf_vectorizer.joblib` â†’ fitted vectorizer

---

### 3ï¸âƒ£ Launch the Streamlit Web App

```bash
streamlit run streamlit.py
```

A browser window will open with:

* **Predicted Rating** (1â€“5 stars)
* **VADER Sentiment Score**
* **Word Cloud** of review highlights

---

## ğŸ’» Modeling Details

| Feature Type          | Source Column       | Method                                                               |
| --------------------- | ------------------- | -------------------------------------------------------------------- |
| **Text Features**     | `consolidated_text` | TF-IDF (max 5000 features, ngram_range=(1,3))                        |
| **Contextual**        | `average_rating`    | Direct numerical input                                               |
| **User Bias Feature** | `user_id`           | Log-transformed review frequency                                     |
| **Final Predictor**   | Combined features   | **Stacking Regressor** *(XGBoost + RandomForest, meta-model: Ridge)* |

âœ… Designed for **low-resource environments (8GB RAM)** with **memory-efficient TF-IDF** and optimized XGBoost settings.

---

## ğŸ“Œ Key Highlights

* ğŸ”„ **End-to-end ML pipeline** (data preprocessing â†’ training â†’ deployment)
* ğŸ§© **Hybrid feature engineering** (text + contextual + user bias)
* âš¡ **Sub-second inference** via Streamlit app
* ğŸ“Š **Explainability features**: VADER sentiment + Word Cloud

---

## ğŸ› ï¸ Tech Stack

* **Python** (pandas, numpy, scikit-learn, nltk)
* **Models**: XGBoost, RandomForest, Ridge
* **Deployment**: Streamlit
* **Visualization**: WordCloud, Matplotlib

---

## ğŸ“¬ Future Improvements

* [ ] Improve RMSE < 0.90 with deep learning models (BERT embeddings)
* [ ] Add more metadata features (category, product title)
* [ ] Deploy with Docker + CI/CD pipeline

---

ğŸ’¡ *Developed as part of an advanced ML pipeline project showcasing hybrid feature engineering for real-world e-commerce data.*
